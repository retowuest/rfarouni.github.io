<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="author" content="Rick Farouni" />
  <meta name="dcterms.date" content="2017-03-20" />
  <title>Brownbag Presentation</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="brownbag_files/reveal.js-3.3.0/css/reveal.css"/>



<link rel="stylesheet" href="brownbag_files/reveal.js-3.3.0/css/theme/sky.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }

  </style>

    <style type="text/css">code{white-space: pre;}</style>

    <link rel="stylesheet" href="styles.css"/>
    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'brownbag_files/reveal.js-3.3.0/css/print/pdf.css' : 'brownbag_files/reveal.js-3.3.0/css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>
    <!--[if lt IE 9]>
    <script src="brownbag_files/reveal.js-3.3.0/lib/js/html5shiv.js"></script>
    <![endif]-->

    <link href="brownbag_files/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Brownbag Presentation</h1>
    <h2 class="author">Rick Farouni</h2>
    <h3 class="date">March 20, 2017</h3>
</section>

<section><section id="a-contemporary-overview-of-latent-generative-models-from-a-probabilistic-perspective" class="titleslide slide level1"><h1>A Contemporary Overview of Latent Generative Models from a Probabilistic Perspective</h1></section><section id="what-is-a-latent-variable" class="slide level2">
<h1>What is a Latent Variable?</h1>
<figure>
<img src="lv.jpg" />
</figure>
</section><section id="what-is-a-latent-variable-model" class="slide level2">
<h1>What is a Latent Variable Model?</h1>
<span class="math display">\[
{\mathbf{y}}\in \mathbb{R}^{N \times P }; {\mathbf{y}}_n \in \mathbb{R}^{P}; {\mathbf{z}}_n \in \mathbb{R}^{D}; {\boldsymbol{\theta}}\in \mathbb{R}^{M}\\
p({\mathbf{y}}_1,\cdots,{\mathbf{y}}_N,{\mathbf{z}}_1,\cdots,{\mathbf{z}}_N,{\boldsymbol{\theta}}) = p({\boldsymbol{\theta}})\prod_{n=1}^N\ p({\mathbf{y}}_n\mid{\mathbf{z}}_n,{\boldsymbol{\theta}})p({\mathbf{z}}_n\mid{\boldsymbol{\theta}})\]</span>
<hr>
<div style="width:600px; height:250px; margin:auto">
<figure>
<img src="lvm.jpg" alt="Graphical Model Representation" /><figcaption>Graphical Model Representation</figcaption>
</figure>
</div>
</section><section id="class-of-latent-variable-models" class="slide level2">
<h1>Class of Latent Variable Models</h1>
<ul>
<li class="fragment">Matrix factorization models (e.g. PCA, Factor Analysis)</li>
<li class="fragment">Multilevel regression models (e.g. random effects model)</li>
<li class="fragment">Time series models (e.g. Hidden Markov Model)</li>
<li class="fragment">Dirichlet process mixture models</li>
<li class="fragment">Deep latent variable models (e.g. VAE)</li>
<li class="fragment">And others …</li>
</ul>
</section><section id="multivariate-models" class="slide level2">
<h1>Multivariate Models</h1>
<p><span class="math display">\[p({\mathbf{y}}_1,\cdots, {\mathbf{y}}_N, {\mathbf{x}}_1,\cdots, {\mathbf{x}}_N, \theta)\]</span></p>
<p><span class="math display">\[\prod_{n=1}^Np({\mathbf{y}}_n \mid f_{\theta}({\mathbf{x}}_n),\theta^{Y})p(\theta^{Y})\prod_{n=1}^N p( {\mathbf{x}}_n \mid \theta^{X})  p(\theta^X)\]</span></p>
</section><section id="multivariate-regression" class="slide level2">
<h1>Multivariate Regression</h1>
<p><span class="math display">\[\prod_{n=1}^N  {\mathcal{N}}_p( {\mathbf{y}}_{n} \mid {\mathbf{B}}{\mathbf{x}}_n, \ {\boldsymbol{\Sigma}})\]</span></p>
</section><section id="reduced-rank-regression" class="slide level2">
<h1>Reduced Rank Regression</h1>
<p><span class="math display">\[\textit{Let } \overset{p\times m}{\mathbf{B}}=\overset{p\times d}{\mathbf{W}}\ \overset{d\times m}{\mathbf{D}}\\
\prod_{n=1}^N  {\mathcal{N}}_p( {\mathbf{y}}_n \mid {\mathbf{W}}{\mathbf{D}}{\mathbf{y}}_n, \ {\boldsymbol{\Sigma}})\]</span></p>
<br> <br>
<hr>
<p><small> <span class="citation" data-cites="izenman2008">Izenman (2008)</span> </small></p>
</section><section id="latent-variable-models" class="slide level2">
<h1>Latent Variable Models</h1>
<p><span class="math display">\[\textit{Let } {{\mathbf{z}}_n}=\overset{d\times m}{\mathbf{D}}\overset{m\times 1}{{\mathbf{y}}_n}\\
\prod_{n=1}^N  {\mathcal{N}}_p( {\mathbf{y}}_n \mid {\mathbf{W}}{\mathbf{z}}_n, \ {\boldsymbol{\Sigma}})\]</span></p>
</section><section id="examples-of-common-latent-variable-models" class="slide level2">
<h1>Examples of Common Latent Variable Models</h1>
</section><section id="principle-component-analysis-pca" class="slide level2">
<h1>Principle Component Analysis (PCA)</h1>
<p><span class="math display">\[
\prod_{n=1}^N  {\mathcal{N}}_p( {\mathbf{y}}_n \mid {\mathbf{W}}{\mathbf{z}}_n, \ \sigma^2\mathbf{I}) \mathcal{N}_d({\mathbf{z}}_n \mid \boldsymbol{0},\,\mathbf{I})
\]</span></p>
<h3 id="as-a-generative-model">As a generative model</h3>
<p><span class="math display">\[
{\mathbf{z}}_n\ \sim\ \mathcal{N}_d(\boldsymbol{0},\,\mathbf{I}) \quad  n=1,\cdots,N \\
{\mathbf{y}}_n \mid  {\mathbf{z}}_n \sim\ \mathcal{N}_p({\mathbf{W}}{\mathbf{z}}_n,\, \sigma^2\mathbf{I})
\]</span></p>
<br> <br>
<hr>
<p><small> <span class="citation" data-cites="tipping1999">Tipping and Bishop (1999)</span> </small></p>
</section><section id="factor-analysis-fa" class="slide level2">
<h1>Factor Analysis (FA)</h1>
<p><span class="math display">\[
\prod_{n=1}^N  {\mathcal{N}}_p( {\mathbf{y}}_n \mid {\mathbf{W}}{\mathbf{z}}_n, \ \operatorname{Diag}(\sigma^2)) \mathcal{N}_d({\mathbf{z}}_n \mid \boldsymbol{0},\,\mathbf{I})
\]</span></p>
<h3 id="as-a-generative-model-1">As a generative model</h3>
<p><span class="math display">\[
{\mathbf{z}}_n\ \sim\ \mathcal{N}_d(\boldsymbol{0},\,\mathbf{I}) \quad n=1,\cdots,N \\
{\mathbf{y}}_n \mid  {\mathbf{z}}_n \sim\ \mathcal{N}_p({\mathbf{W}}{\mathbf{z}}_n,\,\operatorname{Diag}(\sigma^2) )
\]</span></p>
</section><section id="independent-component-analysis-ica" class="slide level2">
<h1>Independent Component Analysis (ICA)</h1>
<p><span class="math display">\[
\prod_{n=1}^N  {\mathcal{N}}_p( {\mathbf{y}}_n \mid {\mathbf{W}}{\mathbf{z}}_n, \ \operatorname{Diag}(\sigma^2)) \prod_{n=1}^N \prod_{d=1}^D \mathcal{GG}_d(z_{d,n} \mid\alpha_d) \quad \alpha_d &lt; 2 
\]</span></p>
<h3 id="as-a-generative-model-2">As a generative model</h3>
<span class="math display">\[
\alpha_d &lt; 2;\quad n=1,\cdots,N \\
z_{d,n}\ \sim\ \mathcal{GG}_d(\alpha_d) \quad d=1:D\\
{\mathbf{y}}_n \mid  {\mathbf{z}}_n\sim\ \mathcal{N}_p({\mathbf{W}}{\mathbf{z}}_n,\, \operatorname{Diag}(\sigma^2))
\]</span> <br>
<hr>
<p><small> <span class="citation" data-cites="Hyvarinen2015">Hyvärinen (2015)</span> </small></p>
</section><section id="canonical-correlation-analysis-cca" class="slide level2">
<h1>Canonical Correlation Analysis (CCA)</h1>
<p><span class="math display">\[
{\mathbf{z}}_n \sim \mathcal{N}_d\left(\boldsymbol{0},\mathbf{I}\right) \quad n=1, \cdots,N\\
\begin{bmatrix}
    {{\mathbf{y}}_n}^{(1)}\mid {\mathbf{z}}_n\\
    {{\mathbf{y}}_n}^{(2)}\mid {\mathbf{z}}_n
\end{bmatrix} \sim \mathcal{N}_{(p1+p2)}\left(\begin{bmatrix}
    \mathbf{W}^{(1)}\\
    \mathbf{W}^{(2)} 
\end{bmatrix} {\mathbf{z}}_n,\begin{bmatrix}
    {\boldsymbol{\Sigma}}^{(1)} &amp; \boldsymbol{0}\\
   \boldsymbol{0} &amp; {\boldsymbol{\Sigma}}^{(2)}
\end{bmatrix}\right) 
\]</span></p>
<br> <br>
<hr>
<p><small> <span class="citation" data-cites="bach2005">Bach and Jordan (2005)</span> </small></p>
</section><section id="deep-latent-gaussian-models-dlgm" class="slide level2">
<h1>Deep Latent Gaussian Models (DLGM)</h1>
<span class="math display">\[\mathbf{z}_n^{(L)}\ \sim\ \mathcal{N}_{d_{(L)}}(\boldsymbol{0},\, \mathbf{I}))  \quad n=1, \cdots,N \\
    {\mathbf{z}}_n^{(l)}\ \sim\ \mathcal{N}_{d_{(l)}}({\mathbf{z}}_n^{(l)} \mid \mathbf{NN}^{(l)}({\mathbf{z}}_n^{(l+1)};{\boldsymbol{\theta}}^{(l)}),\, \Sigma^{(l)} )\quad l=1, \cdots,L-1\\
{\mathbf{y}}_n \mid  {\mathbf{z}}_n \sim\ \mathbf{Expon}_p({\mathbf{y}}_n \mid \mathbf{NN}^{(0)}({\mathbf{z}}_n^{(1)};{\boldsymbol{\theta}}^{(0)}))\\
\]</span>
<hr>
<span class="math display">\[ 
\textit{where } \quad
\mathbf{NN}({\mathbf{z}};\theta) = h_K \circ h_{K-1} \circ \ldots \circ h_0(\mathbf{z}) \\
 \quad h_k({\mathbf{y}}) = \sigma_k(\mathbf{W}^{(k)} {\mathbf{y}}+\mathbf{b}^{(k)})\\  
 {\boldsymbol{\theta}}= \{ (\mathbf{W}^{(k)}, \mathbf{b}^{(k)}) \}_{k=0}^K
\]</span>
<hr>
<p><small> <span class="citation" data-cites="rezende2014">Rezende, Mohamed, and Wierstra (2014)</span> </small></p>
</section><section id="variational-autoencoder-vae" class="slide level2">
<h1>Variational Autoencoder (VAE)</h1>
<p><br> <br></p>
<p><span class="math display">\[\mathbf{z}_n\ \sim\ \mathcal{N}_d(\boldsymbol{0},\, \mathbf{I}))  \quad n=1, \cdots,N\\
{\mathbf{y}}_n \mid  {\mathbf{z}}_n \sim\ \mathcal{N}_p(\mathbf{NN}_{\mu}({\mathbf{z}}_n;{\boldsymbol{\theta}}),\, \mathbf{NN}_{\sigma}(\mathbf{z}_n;{\boldsymbol{\theta}})))
\]</span></p>
<br> <br>
<hr>
<p><small> <span class="citation" data-cites="Kingma2013">Kingma and Welling (2013)</span> </small></p>
</section><section class="slide level2">

<h3 id="recent-extensions"><strong>Recent Extensions</strong></h3>
<small> - DRAW: deep recurrent attention writer (Gregor et al., 2015)</small> <small> - VRNN: Variational recurrent neural network (Chung et al., 2015)</small> <small> - DMM: Deep Markov models (Krishnan et al., 2016)</small>
<div style="width:600px; height:250px; margin:auto">
<figure>
<img src="posteriors.png" alt="Image Credit: Blei et. al. NIPS 2016 Tutorial Slides" /><figcaption>Image Credit: Blei et. al. NIPS 2016 Tutorial Slides</figcaption>
</figure>
</div>
</section></section>
<section><section id="application-of-a-deep-latent-variable-model-to-the-unsupervised-learning-of-chromatin-states" class="titleslide slide level1"><h1>Application of a Deep Latent Variable Model to the Unsupervised Learning of Chromatin States</h1></section><section id="background" class="slide level2">
<h1>Background</h1>
</section><section class="slide level2">

<h3 id="the-general-problem">The General Problem</h3>
<p><em>Molecular phenotype</em> = <span class="math inline">\(\Phi\)</span>( <em>genome, environment</em>)</p>
<div style="width:1000px; height:400px; margin:auto">
<img src="phenotype.jpg" />
</div>
</section><section class="slide level2">

<h3 id="brief-history">Brief History</h3>
<ul>
<li class="fragment">Human Genome Project (2001) <small> Sequence all 3 billion base-pairs of the human genome (1.5% protein coding) </small></li>
<li class="fragment">ENCODE project (2012) <small> Determine the functional role of the remaining 98.5% of the non-coding genome </small></li>
<li class="fragment">PsychENCODE project (2015) <small>How variation in functional genome is associated with psychiatric disorders </small></li>
<li class="fragment">Others Studies <small> How variation in the neuronal functional genome is associated with learning/plasticity and normal/abnormal cognition. See <span class="citation" data-cites="rajarajan2016">Rajarajan et al. (2016)</span> for a review.</small></li>
</ul>
</section><section class="slide level2">

<h3 id="the-specific-computational-problem">The Specific Computational Problem</h3>
<p><em>TF binding</em> = <span class="math inline">\(\Phi_1\)</span>(<em>regulatory DNA</em>)</p>
<p><em>Gene Expression</em> = <span class="math inline">\(\Phi_2\)</span>(<em>TF binding</em>)</p>
<div style="width:400px; height:200px; margin:auto">
<figure>
<img src="DNAtoProtein.png" alt="Central Dogma of Molecular Biology 2.0" /><figcaption>Central Dogma of Molecular Biology 2.0</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="chromatin-architecture">Chromatin Architecture</h3>
<div style="width:900px; height:500px; margin:auto">
<figure>
<img src="chromatin.jpg" alt="Chromatin Architecture and the Functional Genome" /><figcaption>Chromatin Architecture and the Functional Genome</figcaption>
</figure>
</div>
</section><section id="data" class="slide level2">
<h1>Data</h1>
<ul>
<li>A total of 100 ENCODE epigenomic datasets were used
<ul>
<li>10 ENCODE cell types</li>
<li>10 ChIP-seq datasets (genome-wide signal coverage)</li>
</ul></li>
</ul>
</section><section class="slide level2">

<h3 id="cell-types">Cell Types</h3>
<div style="width:700px; height:500px; margin:auto">
<figure>
<img src="1mark10cells.png" alt="UCSC Genome Browser Tracks for the H3k27me3 mark for all 10 cells" /><figcaption>UCSC Genome Browser Tracks for the H3k27me3 mark for all 10 cells</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="epigenetic-marks">Epigenetic Marks</h3>
<div style="width:450px; height:340px; margin:auto">
<figure>
<img src="9marks2cells.png" alt="UCSC Genome Browser Tracks for all 9 marks for GM12878 and H1-hESC cells" /><figcaption>UCSC Genome Browser Tracks for all 9 marks for GM12878 and H1-hESC cells</figcaption>
</figure>
</div>
</section><section id="preprocessing" class="slide level2">
<h1>Preprocessing</h1>
<ol type="1">
<li>Creating a blacklist file of excludable genomic regions</li>
<li>Segment the human reference genome into 200bp bins</li>
<li>Discard regions that overlap the blacklist</li>
<li>Combine 100 bigWig signals into one data-frame</li>
<li>Average the signal over the 200bp segments</li>
<li>Subtract control signal from other 9 signals for each cell-type</li>
<li>Normalize the signals</li>
<li>Create labels from available functional annotation data</li>
</ol>
</section><section class="slide level2">

<h3 id="visualizing-the-observations">Visualizing the Observations</h3>
<div style="width:1000px; height:800px; margin:auto">
<figure>
<img src="observations_enhancers.png" alt="A Sample of 12 Observations from Test Data. Each has 10 cells (rows) x 9 Epigenentic Marks (columns)" /><figcaption>A Sample of 12 Observations from Test Data. Each has 10 cells (rows) x 9 Epigenentic Marks (columns)</figcaption>
</figure>
</div>
</section><section id="model-the-variational-autoencoder" class="slide level2">
<h1>Model: The Variational Autoencoder</h1>
<div style="width:500px; height:360px; margin:auto">
<figure>
<img src="vae.jpg" alt="VAE Model" /><figcaption>VAE Model</figcaption>
</figure>
</div>
</section><section id="generative-network" class="slide level2">
<h1>Generative Network</h1>
<p><span class="math display">\[
p({\mathbf{y}},{\mathbf{z}}) =\prod_{n=1}^N  \mathbf{Bernoulli}_p({\mathbf{y}}_n \mid \mathbf{NN}({\mathbf{z}}_n;{\boldsymbol{\theta}}))\mathcal{N}_d({\mathbf{z}}_n \mid \boldsymbol{0},\,\mathbf{I})
\]</span> <span class="math display">\[ 
\textit{where } \quad
\mathbf{NN}({\mathbf{z}};\theta) = h_K \circ h_{K-1} \circ \ldots \circ h_0(\mathbf{z}) \\
 \quad h_k({\mathbf{y}}) = \sigma_k(\mathbf{W}^{(k)} {\mathbf{y}}+\mathbf{b}^{(k)})\\  
 {\boldsymbol{\theta}}= \{ (\mathbf{W}^{(k)}, \mathbf{b}^{(k)}) \}_{k=0}^K\\
 \textit{is a function parameterized by a deep neural network}
\]</span></p>
</section><section id="variational-approximation-network" class="slide level2">
<h1>Variational Approximation Network</h1>
<p>Since the true posterior is intractable <span class="math display">\[p_\theta(\mathbf{z}_n \mid \mathbf{y}_n) = \frac{p({\mathbf{y}}_n \mid {\mathbf{z}}_n)p({\mathbf{z}}_n)}{p({\mathbf{y}}_n)}\\\]</span></p>
<p>We introduce an approximate posterior distribution <span class="math display">\[q_\nu(\mathbf{z}_n \mid \mathbf{y}_n;\nu) = \mathbf{Bernoulli}_p(\mathbf{NN}({\mathbf{z}}_n;\nu)))\\\]</span></p>
</section><section class="slide level2">

<p>And minimize Kullback–Leibler divergence between the approximate posterior and the true posterior</p>
<div style="width:800px; height:500px; margin:auto">
<figure>
<img src="var_infer.jpg" alt="Image Credit: Blei et. al. NIPS 2016 Tutorial Slides" /><figcaption>Image Credit: Blei et. al. NIPS 2016 Tutorial Slides</figcaption>
</figure>
</div>
</section><section id="variational-inference-for-vae" class="slide level2">
<h1>Variational Inference for VAE</h1>
<p></br></p>
<blockquote>
<p>“Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.” - <strong>John Tukey</strong></p>
</blockquote>
</section><section id="network-architecture" class="slide level2">
<h1>Network Architecture</h1>
<ul>
<li class="fragment"><strong>Generative Model Network</strong>
<ul>
<li class="fragment">Nonlinearities: <em>Input–&gt; Relu–&gt; Relu–&gt; sigmoid</em></li>
<li class="fragment">Layer Size: <em>2 –&gt; 256–&gt; 512–&gt; 90</em></li>
</ul></li>
<li class="fragment"><strong>Variational Approximation Network</strong>
<ul>
<li class="fragment">Nonlinearities: <em>Input -&gt;Relu –&gt;Relu –&gt; (linear, softplus)</em></li>
<li class="fragment">Layer Size: <em>90 –&gt;512 –&gt;256 –&gt;(2, 2)</em></li>
</ul></li>
<li class="fragment">Total Number of Parameters: 1,483,854</li>
</ul>
<hr>
<p></br> <span class="math display">\[\Phi({\mathbf{y}}, \theta) = \rho(W_L(\rho(W_{L-1} \cdots \rho(W_1({\mathbf{y}}))\cdots)\]</span></p>
<small> where <span class="math inline">\(W_l\)</span> is a linear operator and <span class="math inline">\(\rho\)</span> is a pointwise nonlinearity </small>
<hr>
</section><section id="nonlinearities" class="slide level2">
<h1>Nonlinearities</h1>
<div style="width:550px; height:500px; margin:auto">
<figure>
<img src="activations.png" alt="Activation Functions" /><figcaption>Activation Functions</figcaption>
</figure>
</div>
</section><section id="inference" class="slide level2">
<h1>Inference</h1>
<ul>
<li>Tensorflow via Python API</li>
<li>Training Data:
<ul>
<li>All except Chromosomes 1, 8, and 21</li>
<li>Sample Size: 11,748,445</li>
<li>Dimensionality: 90</li>
<li>Validation Split: 80% Training, 20% Validation</li>
</ul></li>
<li>Test Data
<ul>
<li>Chromosomes 1, 8, and 21</li>
<li>Sample Size: 1,946,177 Observations</li>
</ul></li>
</ul>
</section><section id="optimization" class="slide level2">
<h1>Optimization</h1>
<ul>
<li>Minibatch Stochastic Gradient Descent (SGD)
<ul>
<li>Nesterov Accelerated Adaptive Moment Estimation</li>
<li>Batch Size: 256</li>
<li>Number of Updates Per Epoch: 36,713</li>
<li>Computational Cost: ~1 GFLOP per update<br />

<hr>
<div style="width:370px; height:280px; margin:auto">
<figure>
<img src="opt2.gif" alt="Image credit: Alec Radford" /><figcaption>Image credit: Alec Radford</figcaption>
</figure>
</div></li>
</ul></li>
</ul>
</section><section class="slide level2">

<h3 id="projection-of-validation-data-onto-latent-space">Projection of Validation Data onto Latent Space</h3>
<div style="width:1000px; height:800px; margin:auto">
<figure>
<img src="valid_unlabeled.png" alt="Projection of 2,349,696 Observations into 2D Manifold" /><figcaption>Projection of 2,349,696 Observations into 2D Manifold</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="projection-of-test-data-onto-latent-space">Projection of Test Data onto Latent Space</h3>
<div style="width:1000px; height:800px; margin:auto">
<figure>
<img src="test_unlabeled.png" alt="Projection of 1,946,177 Observations into 2D Manifold" /><figcaption>Projection of 1,946,177 Observations into 2D Manifold</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="functional-annotations">Functional Annotations</h3>
<ul>
<li>FANTOM5 Atlas of Active Enhancers (43,011 regions)</li>
<li>CpG islands (52,502 regions)</li>
<li>GENCODE Version 19 Gene Annotations:
<ul>
<li>Coding DNA sequence (CDS)</li>
<li>Promoters</li>
</ul></li>
</ul>
</section><section class="slide level2">

<h3 id="projected-validation-data-labeled-subset">Projected Validation Data (Labeled Subset)</h3>
<div style="width:1000px; height:800px; margin:auto">
<figure>
<img src="valid_labeled.png" alt="Projection of 116,851 Observations with Labels" /><figcaption>Projection of 116,851 Observations with Labels</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="projected-test-data-labeled-subset">Projected Test Data (Labeled Subset)</h3>
<div style="width:1000px; height:800px; margin:auto">
<figure>
<img src="test_labeled.png" alt="Projection of 102,115 Observations with Labels" /><figcaption>Projection of 102,115 Observations with Labels</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="visualizing-the-learned-2-d-manifold">Visualizing the Learned 2-D Manifold</h3>
<div style="width:600px; height:600px; margin:auto">
<figure>
<img src="2dmanifold.png" alt="16 x 16 Grid of Samples from Latent Space" /><figcaption>16 x 16 Grid of Samples from Latent Space</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="visualizing-the-learned-2-d-manifold-1">Visualizing the Learned 2-D Manifold</h3>
<div style="width:600px; height:600px; margin:auto">
<figure>
<img src="2dmanifold_zoom.png" alt="3 x 3 Close-up of Right Side of the Latent Space" /><figcaption>3 x 3 Close-up of Right Side of the Latent Space</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="reconstructing-observations">Reconstructing Observations</h3>
<div style="width:800px; height:800px; margin:auto">
<figure>
<img src="reconstructions.png" alt="Reconstructions of Observations by Projection followed by Sampling from the Latent Manifold" /><figcaption>Reconstructions of Observations by Projection followed by Sampling from the Latent Manifold</figcaption>
</figure>
</div>
</section><section id="application" class="slide level2">
<h1>Application</h1>
<p>Better Unsupervised Learning Methods?</p>
<ul>
<li><strong>ChromHMM</strong> (Ernst J. and Kellis M, 2012): Hidden Markov Model</li>
<li><strong>Segway</strong> (Hoffman et al., 2012): Dynamic Bayesian Network</li>
</ul>
</section><section id="thank-you" class="slide level2">
<h1>Thank You!</h1>
<p></br></p>
<blockquote>
<p>“Information has its own architecture. Each data source, whether imagery, sound, text, has an inner architecture which we should attempt to discover.” - <strong>David Donoho, Plenary Address at ICM 2012</strong></p>
</blockquote>
</section><section id="extra" class="slide level2">
<h1>Extra</h1>
</section><section class="slide level2">

<div style="width:600px; height:600px; margin:auto">
<figure>
<img src="vae.gif" alt="Learning the VAE Latent Space" /><figcaption>Learning the VAE Latent Space</figcaption>
</figure>
</div>
</section><section class="slide level2">

<div style="width:600px; height:600px; margin:auto">
<figure>
<img src="vae.png" alt="VAE’s Approximate Posterior Latent Space (MNIST)" /><figcaption>VAE’s Approximate Posterior Latent Space (MNIST)</figcaption>
</figure>
</div>
</section><section class="slide level2">

<div style="width:800px; height:800px; margin:auto">
<figure>
<img src="vaefaces.jpg" alt="VAE’s Approximate Posterior Latent Space (Faces)" /><figcaption>VAE’s Approximate Posterior Latent Space (Faces)</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="deep-learning-models">Deep learning Models</h3>
<div style="width:900px; height:500px; margin:auto">
<figure>
<img src="CNN.jpg" alt="Deep convolutional neural network (Mallat, 2016)" /><figcaption>Deep convolutional neural network (Mallat, 2016)</figcaption>
</figure>
</div>
</section><section class="slide level2">

<h3 id="why-is-deep-learning-succussful">Why is Deep Learning succussful?</h3>
<p></br> <strong>Beats the curse of dimensionality!</strong> </br> </br></p>
<h3 id="how">How?</h3>
<ol type="1">
<li class="fragment"><strong>Linearizes</strong> intra-class variability while preserving inter-class variability</li>
<li class="fragment"><strong>Regularizes</strong> and incorporates prior information <small> </br> <strong><em>Example</em></strong>: A convolutional layer in a CNN imposes an infinitely strong prior that interactions are only local and equivariant to translation </small></li>
</ol>
</section><section class="slide level2">

<h3 id="learned-representations">Learned Representations</h3>
<div style="width:500px; height:400px; margin:auto">
<figure>
<img src="circleCNN.png" alt="Linearization and Regularization (from ConvnetJS)" /><figcaption>Linearization and Regularization (from ConvnetJS)</figcaption>
</figure>
</div>
</section><section class="slide level2">

<div id="refs" class="references">
<div id="ref-bach2005">
<p>Bach, Francis R, and Michael I Jordan. 2005. “A probabilistic interpretation of canonical correlation analysis.” Technical report 688. Berkeley: Department of Statistics, University of California, Berkeley.</p>
</div>
<div id="ref-Hyvarinen2015">
<p>Hyvärinen, Aapo. 2015. “A unified probabilistic model for independent and principal component analysis.” <em>Advances in Independent Component Analysis and Learning Machines</em>, 1–9.</p>
</div>
<div id="ref-izenman2008">
<p>Izenman, Alan Julian. 2008. <em>Modern Multivariate Statistical Techniques</em>. <em>Regression, Classification and Manifold Learning</em>. Springer.</p>
</div>
<div id="ref-Kingma2013">
<p>Kingma, Diederik P, and Max Welling. 2013. “Auto-Encoding Variational Bayes.” <em>ICLR</em>, no. Ml (December): 1–14.</p>
</div>
<div id="ref-rajarajan2016">
<p>Rajarajan, Prashanth, Sergio Espeso Gil, Kristen J Brennand, and Schahram Akbarian. 2016. “Spatial genome organization and cognition.” <em>Nature Publishing Group</em> 17. doi:<a href="https://doi.org/10.1038/nrn.2016.124">10.1038/nrn.2016.124</a>.</p>
</div>
<div id="ref-rezende2014">
<p>Rezende, Danilo Jimenez, Shakir Mohamed, and Daan Wierstra. 2014. “Stochastic Backpropagation and Approximate Inference in Deep Generative Models.” <em>ArXiv Preprint ArXiv:1401.4082</em>.</p>
</div>
<div id="ref-tipping1999">
<p>Tipping, Michael E., and Christopher M. Bishop. 1999. “Probabilistic Principal Component Analysis.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 61 (3): 611–22.</p>
</div>
</div>
</section></section>
    </div>
  </div>

  <script src="brownbag_files/reveal.js-3.3.0/lib/js/head.min.js"></script>
  <script src="brownbag_files/reveal.js-3.3.0/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: true,
        // Opens links in an iframe preview overlay
        previewLinks: true,
        // Transition style
        transition: 'slide', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom


        chalkboard: {
        },

        keyboard: {
          67: function() { RevealChalkboard.toggleNotesCanvas() },    // toggle notes canvas when 'c' is pressed
          66: function() { RevealChalkboard.toggleChalkboard() }, // toggle chalkboard when 'b' is pressed
          46: function() { RevealChalkboard.clear() },    // clear chalkboard when 'DEL' is pressed
           8: function() { RevealChalkboard.reset() },    // reset chalkboard data on current slide when 'BACKSPACE' is pressed
          68: function() { RevealChalkboard.download() }, // downlad recorded chalkboard drawing when 'd' is pressed
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'brownbag_files/reveal.js-3.3.0/plugin/notes/notes.js', async: true },
          { src: 'brownbag_files/reveal.js-3.3.0/plugin/zoom-js/zoom.js', async: true },
          { src: 'brownbag_files/reveal.js-3.3.0/plugin/chalkboard/chalkboard.js', async: true },
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "brownbag_files/mathjax-local/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
